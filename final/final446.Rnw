\documentclass[12pt]{article}

\usepackage{amssymb,amsmath}
\usepackage{enumerate}
\usepackage{float}
\usepackage{verbatim}
\usepackage{setspace}
\usepackage{multicol}

%% LaTeX margin settings:
  \setlength{\textwidth}{7.0in}
\setlength{\textheight}{9in}
\setlength{\oddsidemargin}{-.5in}
\setlength{\evensidemargin}{0in}
\setlength{\topmargin}{-1.5cm}

%% tell knitr to use smaller font for code chunks
\def\fs{\footnotesize}
\def\R{{\sf R}}
\newcommand{\bfbeta}{\mbox{\boldmath $\beta$}}
\newcommand{\bfD}{\mbox{\boldmath $D$}}
\newcommand{\bfL}{\mbox{\boldmath $L$}}
\newcommand{\bfR}{\mbox{\boldmath $R$}}
\newcommand{\bfmu}{\mbox{\boldmath $\mu$}}
\newcommand{\bfv}{\mbox{\boldmath $V$}}
\newcommand{\bfX}{\mbox{\boldmath $X$}}
\newcommand{\bfy}{\mbox{\boldmath $y$}}
\newcommand{\bfb}{\mbox{\boldmath $b$}}
\newcommand{\ytil}{\mbox{$\tilde{y}$}}

\begin{document}

<<setup, include=FALSE, cache=FALSE>>=
  opts_chunk$set(fig.width=5, fig.height=4, out.width='.5\\linewidth', dev='pdf', concordance=TRUE, size='footnotesize')
options(replace.assign=TRUE,width=72, digits = 3, 
        show.signif.stars = FALSE)
@
  
  
  \begin{center}
\large{Sampling: Final Exam} \\
Leslie Gains-Germain
\end{center}

\begin{doublespacing}

<<readdat, echo=FALSE>>=
setwd("~/Documents/Stat446/final")
cereal <- read.csv("FNL_P1.TXT", head = FALSE)
cereal <- cereal[, 1:12]

golf <- read.table("GOLF.TXT", head = TRUE)
@

<<packages, echo=FALSE, message=FALSE>>=
require(xtable)
@


\begin{enumerate}

\item

\item

\item \begin{enumerate}

\item In the first table, all of the possible samples are shown, along with the probability of drawing each sample (found with replacement). The inclusion probabilities for units I, II, III, IV, V, and VI are shown in the table on the right. The R code for computing these values are shown below.

\begin{multicols}{2}
\begin{table}[H]
\begin{tabular}{ccc}
Sample & Units & $P(S = s)$ \\
\hline
1 & 1,2 & 0.04889 \\
2 & 1,3 & 0.07334 \\
3 & 1,4 & 0.01497 \\
4 & 1,5 & 0.01834 \\
5 & 1,6 & 0.03056 \\
6 & 2,3 & 0.05867 \\
7 & 2,4 & 0.01198 \\
8 & 2,5 & 0.01467 \\
9 & 2,6 & 0.02445 \\
10 & 3,4 & 0.01797 \\
11 & 3,5 & 0.02200 \\
12 & 3,6 & 0.03667 \\
13 & 4,5 & 0.004492 \\
14 & 4,6 & 0.007487 \\
15 & 5,6 & 0.009168 \\
\hline
\end{tabular}
\end{table}

\begin{table}[H]
\begin{tabular}{cc}
Unit & $p_i$ \\
\hline
I & 0.1861 \\
II & 0.1098 \\
III & 0.2087 \\
IV & 0.0569 \\
V & 0.06867 \\
VI & 0.1083 \\
\hline
\end{tabular}
\end{table}
\end{multicols}

\begin{singlespace}
<<areas, echo=TRUE>>=
a1 <- 200
a2 <- 160
a3 <- 240
a4 <- 49
a5 <- 60
a6 <- 100
total.area <- a1 + a2 + a3 + a4 + a5 + a6
p12 <- a1*a2/total.area^2
p13 <- a1*a3/total.area^2
p14 <- a1*a4/total.area^2
p15 <- a1*a5/total.area^2
p16 <- a1*a6/total.area^2
p23 <- a2*a3/total.area^2
p24 <- a2*a4/total.area^2
p25 <- a2*a5/total.area^2
p26 <- a2*a6/total.area^2
p34 <- a3*a4/total.area^2
p35 <- a3*a5/total.area^2
p36 <- a3*a6/total.area^2
p45 <- a4*a5/total.area^2
p46 <- a4*a6/total.area^2
p56 <- a5*a6/total.area^2
pi.1 <- sum(p12, p13, p14, p15, p16)
pi.2 <- sum(p12, p23, p24, p25, p26)
pi.3 <- sum(p13, p23, p34, p35, p36)
pi.4 <- sum(p14, p24, p34, p45, p46)
pi.5 <- sum(p15, p25, p35, p45, p56)
pi.6 <- sum(p16, p26, p36, p46, p56)
pi <- c(pi.1, pi.2, pi.3, pi.4, pi.5, pi.6)
@
\end{singlespace}

\item The table below shows the $y_i/p_i$ values. The R code is shown below.
\begin{singlespace}
<<yvalues, echo=TRUE, results='asis', size='footnotesize'>>=
y1 <- 248
y2 <- 204
y3 <- 305
y4 <- 49
y5 <- 78
y6 <- 126
y <- c(y1, y2, y3, y4, y5, y6)
y.pi <- y/pi
unit <- c("I", "II", "III", "IV", "V", "VI")
xtable(cbind.data.frame(unit, y, "p_i" = pi, "y/p_i" = y.pi))
@
\end{singlespace}

\item Yes, Hansen Hurwitz estimation will provide an estimate of $\bar{y}_U$ with small variance because the selection probabilities $p_i$ are proportional to the $y_i$ values. The estimated variance of the Hansen-Hurwitz estimator of $\bar{y}_U$ is 

\end{enumerate}

\end{enumerate}

\end{doublespacing}

{\bf \large R code appendix}




\end{document}